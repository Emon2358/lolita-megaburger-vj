import cv2
import numpy as np
import random
import sys
import time
import os

# --- ğŸ’¡ è¨­å®šé …ç›® ---
TOLERANCE = 50                 # è‰²è·é›¢ã®é–¾å€¤ï¼ˆå¤§ãã„ã»ã©åºƒãé€éï¼‰
CHANGE_INTERVAL_FRAMES = 30    # ä½•ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«æ¬¡ã®ç›®æ¨™è‰²ã¸ç§»è¡Œï¼ˆã“ã“ã‚’å¤§ããã™ã‚‹ã¨ã‚†ã£ãã‚Šå¤‰åŒ–ï¼‰
TRANSITION_FRAMES = 15         # è‰²ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã¨ãã®è£œé–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆæ»‘ã‚‰ã‹ã•ï¼‰
BLUR_KERNEL = max(3, int(TOLERANCE // 8) * 2 + 1)  # ãƒã‚¹ã‚¯ã‚’ã¼ã‹ã™ãŸã‚ã®ã‚«ãƒ¼ãƒãƒ«ï¼ˆå¥‡æ•°ï¼‰
# --- åŸºæœ¬è¨­å®š ---
INPUT_VIDEO_FG = 'video1.mp4'
INPUT_VIDEO_BG = 'video2.mp4'
OUTPUT_VIDEO = 'final_video.mp4'

def rand_bgr():
    return np.array([random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)], dtype=np.uint8)

def loop_reset(cap):
    # å‹•ç”»ãŒçµ‚ã‚ã£ãŸã‚‰å…ˆé ­ã«æˆ»ã—ã¦ãƒ«ãƒ¼ãƒ—ã™ã‚‹ï¼ˆèƒŒæ™¯ãŒçŸ­ã„å ´åˆã«ä¾¿åˆ©ï¼‰
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

def process_video():
    # reproducible ã§ã¯ãªãæ¯å›å¤‰ã‚ã‚‹ä¹±æ•°ã«ã™ã‚‹ï¼ˆGitHub Actionsã§ã‚‚å¤§ä¸ˆå¤«ï¼‰
    random.seed(time.time() + os.getpid())

    cap_fg = cv2.VideoCapture(INPUT_VIDEO_FG)
    cap_bg = cv2.VideoCapture(INPUT_VIDEO_BG)

    if not cap_fg.isOpened():
        print(f"ã‚¨ãƒ©ãƒ¼: {INPUT_VIDEO_FG} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    if not cap_bg.isOpened():
        print(f"ã‚¨ãƒ©ãƒ¼: {INPUT_VIDEO_BG} ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    width = int(cap_fg.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap_fg.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap_fg.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap_fg.get(cv2.CAP_PROP_FRAME_COUNT))

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))

    print("å‹•ç”»å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    
    frame_count = 0

    # è‰²ã®ç®¡ç†ï¼ˆç¾åœ¨è‰²ã¨ç›®æ¨™è‰²ã‚’ç”¨æ„ã—ã¦è£œé–“ï¼‰
    current_color = rand_bgr().astype(np.float32)
    target_color = rand_bgr().astype(np.float32)
    transition_progress = 1.0  # 0..1, 1=åˆ°é”æ¸ˆã¿

    while True:
        ret_fg, frame_fg = cap_fg.read()
        ret_bg, frame_bg = cap_bg.read()

        if not ret_fg:
            break
        if not ret_bg:
            # èƒŒæ™¯ã‚’ãƒ«ãƒ¼ãƒ—ã•ã›ã‚‹ï¼ˆèƒŒæ™¯ãŒçŸ­ã„å ´åˆï¼‰
            loop_reset(cap_bg)
            ret_bg, frame_bg = cap_bg.read()
            if not ret_bg:
                print("èƒŒæ™¯ãƒ“ãƒ‡ã‚ªã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                break

        frame_count += 1
        sys.stdout.write(f"\rãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ä¸­: {frame_count} / {total_frames}")
        sys.stdout.flush()

        # ãƒ•ãƒ¬ãƒ¼ãƒ å¹…åˆã‚ã›
        frame_bg_resized = cv2.resize(frame_bg, (width, height))

        # CHANGE_INTERVAL_FRAMESã”ã¨ã«æ–°ã—ã„ target_color ã‚’é¸ã¶ï¼ˆæ»‘ã‚‰ã‹ã«è£œé–“ï¼‰
        if frame_count % CHANGE_INTERVAL_FRAMES == 0:
            target_color = rand_bgr().astype(np.float32)
            transition_progress = 0.0

        # è£œé–“å‡¦ç†ï¼ˆTRANSITION_FRAMES ã‚’ä½¿ã£ã¦æ»‘ã‚‰ã‹ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼‰
        if transition_progress < 1.0:
            transition_progress += 1.0 / max(1, TRANSITION_FRAMES)
            t = min(1.0, transition_progress)
            current_color = (1 - t) * current_color + t * target_color
        else:
            # åˆ°é”æ¸ˆã¿ãªã‚‰ current_color ã‚’ä¿æŒ
            current_color = current_color

        # BGR è·é›¢ã«ã‚ˆã‚‹ã‚½ãƒ•ãƒˆãƒã‚¹ã‚¯
        f = frame_fg.astype(np.int16)  # avoid overflow
        c = current_color.astype(np.int16)
        diff = f - c  # shape (h,w,3)
        dist = np.linalg.norm(diff, axis=2).astype(np.float32)  # Euclidean distance

        # alpha: 0..1, 1 ã®ã¨ã“ã‚ãŒèƒŒæ™¯ç½®æ›ï¼ˆè‰²ãŒè¿‘ã„ã»ã©1ã«ï¼‰
        alpha = np.clip(1.0 - (dist / float(max(1, TOLERANCE))), 0.0, 1.0)

        # ã¼ã‹ã—ï¼ˆã‚¨ãƒƒã‚¸ã‚’æŸ”ã‚‰ã‹ãã™ã‚‹ï¼‰
        alpha_blur = cv2.GaussianBlur(alpha, (BLUR_KERNEL, BLUR_KERNEL), 0)

        # alpha ã‚’ 3 ãƒãƒ£ãƒãƒ«åŒ–ã—ã¦åˆæˆ
        alpha_3 = alpha_blur[..., np.newaxis]
        fg_f = frame_fg.astype(np.float32)
        bg_f = frame_bg_resized.astype(np.float32)
        final_f = fg_f * (1.0 - alpha_3) + bg_f * alpha_3
        final_frame = np.clip(final_f, 0, 255).astype(np.uint8)

        out.write(final_frame)

    print(f"\nå‹•ç”»å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'{OUTPUT_VIDEO}' ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

    cap_fg.release()
    cap_bg.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    process_video()
